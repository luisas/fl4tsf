{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28f2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/bin\")\n",
    "sys.path.append(os.getcwd()) \n",
    "import torch\n",
    "\n",
    "from flower.task import Net, train\n",
    "import torch\n",
    "# import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.dataset_utils import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib.physionet import PhysioNet, variable_time_collate_fn, get_data_min_max\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "from lib import utils\n",
    "from lib.dataset_utils import store_dataset_physionet\n",
    "\n",
    "path_prefix = \"/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/data\"\n",
    "prefix = \"physionet\"\n",
    "batch_size = 64\n",
    "classif = False\n",
    "noise_weight = 0.1\n",
    "max_t_extrap = 5\n",
    "n_total_tp = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "amp_start = 1.0\n",
    "amp_end = 1.0 \n",
    "freq_start =1.0\n",
    "freq_end = freq_start\n",
    "epochs = 5\n",
    "batch_size = 3\n",
    "sample_tp = 0.9\n",
    "n_samples = 4\n",
    "max_t_extrap = 50\n",
    "lr_val = 0.01\n",
    "cut_tp = None\n",
    "extrap = None\n",
    "\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace()\n",
    "args.sample_tp = 0\n",
    "args.cut_tp = None\n",
    "args.extrap = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011867cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_75873/192455421.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data_0 = torch.load(f\"{path_prefix}/{prefix}/client_0_train.pt\")\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_75873/192455421.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data_1 = torch.load(f\"{path_prefix}/{prefix}/client_1_train.pt\")\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_75873/192455421.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_min = torch.load(f\"{path_prefix}/{prefix}/client_0_data_min.pt\")\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_75873/192455421.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_max = torch.load(f\"{path_prefix}/{prefix}/client_0_data_max.pt\")\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load data\n",
    "################################################################\n",
    "train_data_0 = torch.load(f\"{path_prefix}/{prefix}/client_0_train.pt\")\n",
    "train_data_1 = torch.load(f\"{path_prefix}/{prefix}/client_1_train.pt\")\n",
    "# now they are the same so i can use one\n",
    "data_min = torch.load(f\"{path_prefix}/{prefix}/client_0_data_min.pt\")\n",
    "data_max = torch.load(f\"{path_prefix}/{prefix}/client_0_data_max.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628fab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_55284/2981217546.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_min = torch.load(f\"{path_prefix}/{prefix}/client_0_data_min.pt\")\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_55284/2981217546.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_max = torch.load(f\"{path_prefix}/{prefix}/data_max.pt\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/data/physionet/data_max.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TEST \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m################################################################\u001b[39;00m\n\u001b[1;32m      4\u001b[0m data_min \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/client_0_data_min.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m data_max \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_max.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m train_data_0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/client_0_train.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_data_0, batch_size\u001b[38;5;241m=\u001b[39m batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m batch: variable_time_collate_fn(batch, args, device, data_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         data_min \u001b[38;5;241m=\u001b[39m data_min, data_max \u001b[38;5;241m=\u001b[39m data_max))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/data/physionet/data_max.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data_0, batch_size= batch_size, shuffle=False, \n",
    "    collate_fn= lambda batch: variable_time_collate_fn(batch, args, device, data_type = \"train\",\n",
    "        data_min = data_min, data_max = data_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "690125d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration: {'dataset_name': 'freq_amp_decay_maxfreq_0.1', 'data_folder': '../data/freq_amp_decay_maxfreq_0.1', 'sample_tp': '0.5', 'lr': '0.01', 'lrdecay': '0.99', 'cut_tp': None, 'batch_size': '50', 'extrap': False, 'obsrv_std': '0.01', 'poisson': True, 'rec_layers': '1', 'gen_layers': '1', 'units': '100', 'gru_units': '100', 'latents': '10', 'rec_dims': '20', 'z0_encoder': 'odernn', 'train_classif_w_reconstr': False, 'classif': False, 'linear_classif': False, 'classif_per_tp': False, 'n_labels': '1', 'input_dim': '41', 'aggregation': 'FedAvg', 'storeweights': False, 'alpha': '0.5', 'localepochs': '3', 'serverrounds': '3', 'fractionfit': '1.0', 'fractionevaluate': '1.0', 'device': 'cpu', 'use_wandb': False, 'gradientclipping': False, 'decay_onset': '100'}\n",
      "20\n",
      "82\n",
      "100\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n",
      "Running reconstruction for Latent ODE model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n\u001b[0;32m----> 2\u001b[0m loss_training \u001b[38;5;241m=\u001b[39m train(model, train_dataloader, train_dataloader, \u001b[38;5;241m2\u001b[39m, lr \u001b[38;5;241m=\u001b[39m lr_val, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/flower/task.py:119\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, valloader, epochs, lr, device, loss_per_epoch)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m    118\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmove_to_device(batch_dict, device)\n\u001b[0;32m--> 119\u001b[0m train_res \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mcompute_all_losses(batch_dict, n_traj_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, kl_coef \u001b[38;5;241m=\u001b[39m kl_coef)\n\u001b[1;32m    120\u001b[0m train_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Collect gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/base_models.py:289\u001b[0m, in \u001b[0;36mVAE_Baseline.compute_all_losses\u001b[0;34m(self, batch_dict, n_traj_samples, kl_coef)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Compute likelihood of all the points\u001b[39;00m\n\u001b[1;32m    284\u001b[0m rec_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gaussian_likelihood(\n\u001b[1;32m    285\u001b[0m \tbatch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_to_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m], pred_y,\n\u001b[1;32m    286\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_predicted_data\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 289\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mse(\n\u001b[1;32m    290\u001b[0m \tbatch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_to_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m], pred_y,\n\u001b[1;32m    291\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_predicted_data\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    293\u001b[0m pois_log_likelihood \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m0.\u001b[39m])\u001b[38;5;241m.\u001b[39mto(get_device(batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_to_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poisson_proc:\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/base_models.py:251\u001b[0m, in \u001b[0;36mVAE_Baseline.get_mse\u001b[0;34m(self, truth, pred_y, mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mrepeat(pred_y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# Compute likelihood of the data under the predictions\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m log_density_data \u001b[38;5;241m=\u001b[39m compute_mse(pred_y, truth_repeated, mask \u001b[38;5;241m=\u001b[39m mask)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# shape: [1]\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(log_density_data)\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/likelihood_eval.py:231\u001b[0m, in \u001b[0;36mcompute_mse\u001b[0;34m(mu, data, mask)\u001b[0m\n\u001b[1;32m    228\u001b[0m \tres \u001b[38;5;241m=\u001b[39m mse(mu_flat, data_flat)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m \t\u001b[38;5;66;03m# Compute the likelihood per patient so that we don't priorize patients with more measurements\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m \tres \u001b[38;5;241m=\u001b[39m compute_masked_likelihood(mu, data, mask, mse)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/likelihood_eval.py:157\u001b[0m, in \u001b[0;36mcompute_masked_likelihood\u001b[0;34m(mu, data, mask, likelihood_func)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# shape: [n_traj*n_traj_samples, 1]\u001b[39;00m\n\u001b[1;32m    156\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(res, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(get_device(data))\n\u001b[0;32m--> 157\u001b[0m res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mreshape((n_traj_samples, n_traj, n_dims))\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Take mean over the number of dimensions\u001b[39;00m\n\u001b[1;32m    159\u001b[0m res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(res, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# !!!!!!!!!!! changed from sum to mean\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "loss_training = train(model, train_dataloader, train_dataloader, 2, lr = lr_val, device = \"cpu\", loss_per_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "total_dataset = torch.load(os.path.join(path_prefix, prefix, \"total_data.pt\"))\n",
    "# Shuffle and split\n",
    "\n",
    "record_id, tt, vals, mask, labels = train_data[0]\n",
    "\n",
    "\n",
    "n_samples = len(total_dataset)\n",
    "data_min, data_max = get_data_min_max(total_dataset)\n",
    "# laod train and test data\n",
    "train_dataloader = DataLoader(train_data, batch_size= batch_size, shuffle=False, \n",
    "    collate_fn= lambda batch: variable_time_collate_fn(batch, args, device, data_type = \"train\",\n",
    "        data_min = data_min, data_max = data_max))\n",
    "test_dataloader = DataLoader(test_data, batch_size = n_samples, shuffle=False, \n",
    "    collate_fn= lambda batch: variable_time_collate_fn(batch, args, device, data_type = \"test\",\n",
    "        data_min = data_min, data_max = data_max))\n",
    "model= Net()\n",
    "dataset_name = \"test\"\n",
    "\n",
    "# if not classif:\n",
    "#     # Concatenate samples from original Train and Test sets\n",
    "#     # Only 'training' physionet samples are have labels. Therefore, if we do classifiction task, we don't need physionet 'test' samples.\n",
    "#     total_dataset = total_dataset + test_dataset_obj[:len(test_dataset_obj)]\n",
    "\n",
    "# total_data_path = os.path.join(path_prefix, prefix, \"total_data.pt\")\n",
    "# subset_total = total_dataset[1:1000]\n",
    "# torch.save(subset_total, total_data_path)\n",
    "\n",
    "# load tot\n",
    "\n",
    "# # # save train dataloader \n",
    "# train_data_path = os.path.join(path_prefix, prefix, \"train_data.pt\")\n",
    "# subset_train = train_data[1:10]\n",
    "# torch.save(subset_train, train_data_path)\n",
    "# # save test dataloader\n",
    "# test_data_path = os.path.join(path_prefix, prefix, \"test_data.pt\")\n",
    "# subset_test = test_data[1:10]\n",
    "# torch.save(subset_test, test_data_path)\n",
    "\n",
    "#total_dataset = total_dataset + test_dataset_obj[:len(test_dataset_obj)]\n",
    "\n",
    "# attr_names = train_dataset_obj.params\n",
    "# data_objects = {\"dataset_obj\": train_dataset_obj, \n",
    "#             \"train_dataloader\": utils.inf_generator(train_dataloader), \n",
    "#             \"test_dataloader\": utils.inf_generator(test_dataloader),\n",
    "#             \"input_dim\": input_dim,\n",
    "#             \"n_train_batches\": len(train_dataloader),\n",
    "#             \"n_test_batches\": len(test_dataloader),\n",
    "#             \"attr\": attr_names, #optional\n",
    "#             \"classif_per_tp\": False, #optional\n",
    "#             \"n_labels\": 1} #optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d213e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 41])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48114a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n",
      "Computing losses for VAE baseline\n",
      "Running reconstruction for Latent ODE model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_training \u001b[38;5;241m=\u001b[39m train(model, train_dataloader, test_dataloader, \u001b[38;5;241m5\u001b[39m, lr \u001b[38;5;241m=\u001b[39m lr_val, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/flower/task.py:119\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, valloader, epochs, lr, device, loss_per_epoch)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m    118\u001b[0m batch_dict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmove_to_device(batch_dict, device)\n\u001b[0;32m--> 119\u001b[0m train_res \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mcompute_all_losses(batch_dict, n_traj_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, kl_coef \u001b[38;5;241m=\u001b[39m kl_coef)\n\u001b[1;32m    120\u001b[0m train_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Collect gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/base_models.py:261\u001b[0m, in \u001b[0;36mVAE_Baseline.compute_all_losses\u001b[0;34m(self, batch_dict, n_traj_samples, kl_coef)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_all_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_dict, n_traj_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m):\n\u001b[1;32m    258\u001b[0m \t\u001b[38;5;66;03m# Condition on subsampled points\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \t\u001b[38;5;66;03m# Make predictions for all the points\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing losses for VAE baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m \tpred_y, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reconstruction(batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtp_to_predict\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    262\u001b[0m \t\tbatch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved_data\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved_tp\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    263\u001b[0m \t\tmask \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m], n_traj_samples \u001b[38;5;241m=\u001b[39m n_traj_samples,\n\u001b[1;32m    264\u001b[0m \t\tmode \u001b[38;5;241m=\u001b[39m batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    266\u001b[0m \tfp_mu, fp_std, fp_enc \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_point\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    267\u001b[0m \tfp_std \u001b[38;5;241m=\u001b[39m fp_std\u001b[38;5;241m.\u001b[39mabs()\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/latent_ode.py:86\u001b[0m, in \u001b[0;36mLatentODE.get_reconstruction\u001b[0;34m(self, time_steps_to_predict, truth, truth_time_steps, mask, n_traj_samples, run_backwards, mode)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq_solver\u001b[38;5;241m.\u001b[39mode_func\u001b[38;5;241m.\u001b[39mnsteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Shape of sol_y [n_traj_samples, n_samples, n_timepoints, n_latents]\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m sol_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq_solver(first_point_enc_aug, time_steps_to_predict)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poisson_proc:\n\u001b[1;32m     89\u001b[0m \tsol_y, log_lambda_y, int_lambda, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq_solver\u001b[38;5;241m.\u001b[39mode_func\u001b[38;5;241m.\u001b[39mextract_poisson_rate(sol_y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/diffeq_solver.py:40\u001b[0m, in \u001b[0;36mDiffeqSolver.forward\u001b[0;34m(self, first_point, time_steps_to_predict, backwards)\u001b[0m\n\u001b[1;32m     37\u001b[0m n_traj_samples, n_traj \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m n_dims \u001b[38;5;241m=\u001b[39m first_point\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m odeint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mode_func, first_point, time_steps_to_predict, \n\u001b[1;32m     41\u001b[0m \trtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modeint_rtol, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modeint_atol, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mode_method)\n\u001b[1;32m     42\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m pred_y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mmean(pred_y[:, :, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;241m-\u001b[39m first_point) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:80\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     77\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate(t)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:34\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 34\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_advance(t[i])\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:246\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adaptive_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state)\n\u001b[1;32m    247\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:311\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    306\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m _runge_kutta_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, y0, f0, t0, dt, t1, tableau\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtableau)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    321\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:78\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     76\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m     77\u001b[0m     yi \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (beta_i \u001b[38;5;241m*\u001b[39m dt), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview_as(f0)\n\u001b[0;32m---> 78\u001b[0m     f \u001b[38;5;241m=\u001b[39m func(ti, yi, perturb\u001b[38;5;241m=\u001b[39mperturb)\n\u001b[1;32m     79\u001b[0m     k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tableau\u001b[38;5;241m.\u001b[39mbeta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_func(t, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/ode_func.py:37\u001b[0m, in \u001b[0;36mODEFunc.forward\u001b[0;34m(self, t_local, y, backwards)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t_local, y, backwards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\tPerform one step in solving ODE. Given current data point y and current time point t_local, returns gradient dy/dt at this time point\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m\tt_local: current time point\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\ty: value at the current time point\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \tgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_ode_gradient_nn(t_local, y)\n\u001b[1;32m     38\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     39\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m backwards:\n",
      "File \u001b[0;32m~/Desktop/nygc/cluster/projects/fl4tsf/bin/lib/ode_func.py:44\u001b[0m, in \u001b[0;36mODEFunc.get_ode_gradient_nn\u001b[0;34m(self, t_local, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ode_gradient_nn\u001b[39m(\u001b[38;5;28mself\u001b[39m, t_local, y):\n\u001b[0;32m---> 44\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_net(y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_training = train(model, train_dataloader, test_dataloader, 2, lr = lr_val, device = \"cpu\", loss_per_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = utils.inf_generator(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8068ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59ff459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = element['observed_data'][0]\n",
    "e1 = element['observed_data'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faf14d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8889e-01, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 9.0909e-04,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.6364e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.5455e-03,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb3cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example = train_data[4]\n",
    "\n",
    "# time_steps = example[1]\n",
    "# data = example[2]\n",
    "# mask = example[3]\n",
    "\n",
    "# features =  list(range(len(attr_names)))\n",
    "\n",
    "# name_features = [ \"HR\" ]\n",
    "\n",
    "# for i in features:\n",
    "#     feature_name = attr_names[i]\n",
    "#     plt.figure(figsize=(11, 1))\n",
    "#     # make a scatter plot\n",
    "#     plt.scatter(time_steps[mask[:, i] == 1], data[mask[:, i] == 1, i], color='red', s=1, label='Observed')\n",
    "#     # make a line plot for the whole time series but not plottting the zeros \n",
    "#     plot_data = data[:, i][mask[:, i] == 1]\n",
    "#     plt.plot(time_steps[mask[:, i] == 1], plot_data, color='blue', linewidth=0.5, label='Full time series')\n",
    "#     plt.xlabel('Time (normalized)')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.title(f'{feature_name}')\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# def run_centralized(train_loader, test_loader, lr = 0.01, epochs = 2, device = \"cpu\"):\n",
    "#     model = Net()\n",
    "#     dataset_name = \"test\"\n",
    "#     # train\n",
    "#     loss_training = train(model, train_loader, test_loader, epochs, lr, device, loss_per_epoch=True)\n",
    "\n",
    "#     avg_loss, nodesolves, metric_dict = loss_training\n",
    "#     train_loss = metric_dict[\"train_loss\"]\n",
    "#     train_mse = metric_dict[\"train_mse\"]\n",
    "#     val_loss = metric_dict[\"val_loss\"]\n",
    "#     val_mse = metric_dict[\"val_mse\"]\n",
    "\n",
    "#     print(f\"Nodesolves: {nodesolves}\")\n",
    "\n",
    "#     df = pd.DataFrame({\"train_loss\": train_loss, \"train_mse\": train_mse, \"val_loss\": val_loss, \"val_mse\": val_mse, \"nodesolves\": nodesolves})\n",
    "#     return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
