{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a77b00",
   "metadata": {},
   "source": [
    "# Federated learning monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fc68c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "# set cwd\n",
    "os.chdir(\"/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "419ed36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results_manual/periodic/federated_training/FedODE/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32_clipping_True/federated_outputs/results.json',\n",
       " '../results_manual/periodic/federated_training/FedODE/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32_clipping_False/federated_outputs/results.json',\n",
       " '../results_manual/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32_clipping_True/federated_outputs/results.json',\n",
       " '../results_manual/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32_clipping_False/federated_outputs/results.json']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_avg = glob.glob(f\"../results_manual/**/federated_training/**/results.json\", recursive=True)\n",
    "# keep the one that has 15_rounds\n",
    "fed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d56d4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_loss_file(file):\n",
    "    # Read the meta.csv file\n",
    "    meta_file = file.replace(\"results.json\", \"meta.csv\")\n",
    "    meta_data = pd.read_csv(meta_file)\n",
    "    lr = meta_data['lr'].item()\n",
    "    batch_size = meta_data['batch_size'].item()\n",
    "    clipping = meta_data['gradientclipping'].item()\n",
    "    \n",
    "    # Read the results.json file\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Plot centralized evaluate\n",
    "    df_centralized_evaluate = pd.DataFrame(data['centralized_evaluate'])\n",
    "    df_federated_evaluate = pd.DataFrame(data['federated_evaluate'])\n",
    "    # Add the learning rate to the DataFrame\n",
    "    df_federated_evaluate['lr'] = lr\n",
    "    df_centralized_evaluate['lr'] = lr\n",
    "    # Add the batch size to the DataFrame\n",
    "    df_federated_evaluate['batch_size'] = batch_size\n",
    "    df_centralized_evaluate['batch_size'] = batch_size\n",
    "    # Add the clipping to the DataFrame\n",
    "    df_federated_evaluate['clipping'] = clipping\n",
    "    df_centralized_evaluate['clipping'] = clipping\n",
    "\n",
    "    # Aggregation column \n",
    "    # Check if file contins \"FedAvg\" in the path name\n",
    "    if \"FedAvg\" in file:\n",
    "        # if the path name contains \"FedAvg\" then add aggregation column \"FedAvg\"\n",
    "        df_federated_evaluate['aggregation'] = \"FedAvg\"\n",
    "        df_centralized_evaluate['aggregation'] = \"FedAvg\"\n",
    "    else:\n",
    "        # if the path name does not contain \"FedAvg\" then add aggregation column \"FedProx\"\n",
    "        df_federated_evaluate['aggregation'] = \"FedODE\"\n",
    "        df_centralized_evaluate['aggregation'] = \"FedODE\"\n",
    "\n",
    "\n",
    "    # if the path name contains \"FedAvg\" then add aggregation column \"FedAvg\"\n",
    "\n",
    "    # combine lr, batch size and clipping into one column\n",
    "    df_federated_evaluate['hyperparameters'] = df_federated_evaluate.apply(lambda x: f\"lr: {x['lr']}, batch_size: {x['batch_size']}, clipping: {x['clipping']}\", axis=1)\n",
    "    df_centralized_evaluate['hyperparameters'] = df_centralized_evaluate.apply(lambda x: f\"lr: {x['lr']}, batch_size: {x['batch_size']}, clipping: {x['clipping']}\", axis=1)\n",
    "    \n",
    "    df_federated_evaluate['type'] = \"federated\"\n",
    "    df_centralized_evaluate['type'] = \"centralized\"\n",
    "\n",
    "    # modify centralized_loss into loss\n",
    "    df_centralized_evaluate.rename(columns={'centralized_loss': 'loss'}, inplace=True)\n",
    "    # modify federated_loss into loss\n",
    "    df_federated_evaluate.rename(columns={'federated_evaluate_loss': 'loss'}, inplace=True)\n",
    "\n",
    "    return df_centralized_evaluate, df_federated_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34353c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4b168722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>loss</th>\n",
       "      <th>centralized_accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>clipping</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>type</th>\n",
       "      <th>federated_evaluate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1200.956194</td>\n",
       "      <td>0.242023</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>380.238316</td>\n",
       "      <td>0.078365</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>345.030413</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>414.678885</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>328.301583</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>668.438293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.134158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>656.752177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.132232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>656.186056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.131775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>660.881877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.132512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>658.641195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.132770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    round         loss  centralized_accuracy    lr  batch_size  clipping  \\\n",
       "0       0  1200.956194              0.242023  0.01          32      True   \n",
       "1       1   380.238316              0.078365  0.01          32      True   \n",
       "2       2   345.030413              0.070026  0.01          32      True   \n",
       "3       3   414.678885              0.083736  0.01          32      True   \n",
       "4       4   328.301583              0.066225  0.01          32      True   \n",
       "..    ...          ...                   ...   ...         ...       ...   \n",
       "10     11   668.438293                   NaN  0.01          32     False   \n",
       "11     12   656.752177                   NaN  0.01          32     False   \n",
       "12     13   656.186056                   NaN  0.01          32     False   \n",
       "13     14   660.881877                   NaN  0.01          32     False   \n",
       "14     15   658.641195                   NaN  0.01          32     False   \n",
       "\n",
       "   aggregation                            hyperparameters         type  \\\n",
       "0       FedODE   lr: 0.01, batch_size: 32, clipping: True  centralized   \n",
       "1       FedODE   lr: 0.01, batch_size: 32, clipping: True  centralized   \n",
       "2       FedODE   lr: 0.01, batch_size: 32, clipping: True  centralized   \n",
       "3       FedODE   lr: 0.01, batch_size: 32, clipping: True  centralized   \n",
       "4       FedODE   lr: 0.01, batch_size: 32, clipping: True  centralized   \n",
       "..         ...                                        ...          ...   \n",
       "10      FedAvg  lr: 0.01, batch_size: 32, clipping: False    federated   \n",
       "11      FedAvg  lr: 0.01, batch_size: 32, clipping: False    federated   \n",
       "12      FedAvg  lr: 0.01, batch_size: 32, clipping: False    federated   \n",
       "13      FedAvg  lr: 0.01, batch_size: 32, clipping: False    federated   \n",
       "14      FedAvg  lr: 0.01, batch_size: 32, clipping: False    federated   \n",
       "\n",
       "    federated_evaluate_accuracy  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "..                          ...  \n",
       "10                     0.134158  \n",
       "11                     0.132232  \n",
       "12                     0.131775  \n",
       "13                     0.132512  \n",
       "14                     0.132770  \n",
       "\n",
       "[124 rows x 10 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_centralized_evaluate = pd.DataFrame()\n",
    "df_federated_evaluate = pd.DataFrame()\n",
    "for file in fed_avg:\n",
    "    df_centralized_evaluate_temp, df_federated_evaluate_temp = read_loss_file(file)\n",
    "    df_centralized_evaluate = pd.concat([df_centralized_evaluate, df_centralized_evaluate_temp])\n",
    "    df_federated_evaluate = pd.concat([df_federated_evaluate, df_federated_evaluate_temp])\n",
    "# plot the loss\n",
    "# plot the loss by hyperparameters\n",
    "# merge the two dataframes\n",
    "# append dataframes\n",
    "df = pd.concat([df_centralized_evaluate, df_federated_evaluate])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb16d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lr 0.01 batch size 32 clipping True \n",
    "df_test = df[df['hyperparameters'] == \"lr: 0.01, batch_size: 32, clipping: True\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7fb746f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.lineplot(\n",
    "    data=df_test[df_test['type'] == \"federated\"],\n",
    "    x='round',\n",
    "    y='loss',\n",
    "    hue='aggregation',  # Automatically creates different colors\n",
    "    palette='tab10'  # Optional: choose color palette\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_test[df_test['type'] == \"centralized\"],\n",
    "    x='round',\n",
    "    y='loss',\n",
    "    hue='aggregation',  # Automatically creates different colors\n",
    "    palette='tab10'  # Optional: choose color palette\n",
    ")\n",
    "\n",
    "plt.ylim(bottom=0)\n",
    "plt.xticks(ticks=range(0, df_federated_evaluate['round'].max() + 1, 25))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Centralized Training Loss')\n",
    "plt.tight_layout()\n",
    "# log y\n",
    "# legend outside\n",
    "plt.legend(title = \"lr, clipping, batch size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# x log\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "449e5457",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `centralized_loss` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(data\u001b[38;5;241m=\u001b[39mdf_centralized_evaluate, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcentralized_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCentralized Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(data\u001b[38;5;241m=\u001b[39mdf_federated_evaluate, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfederated_evaluate_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFederated Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Set the title and labels\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/relational.py:485\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlineplot\u001b[39m(\n\u001b[1;32m    472\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    473\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# Handle deprecation of ci parameter\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     errorbar \u001b[38;5;241m=\u001b[39m _deprecate_ci(errorbar, ci)\n\u001b[0;32m--> 485\u001b[0m     p \u001b[38;5;241m=\u001b[39m _LinePlotter(\n\u001b[1;32m    486\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    487\u001b[0m         variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    488\u001b[0m             x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, hue\u001b[38;5;241m=\u001b[39mhue, size\u001b[38;5;241m=\u001b[39msize, style\u001b[38;5;241m=\u001b[39mstyle, units\u001b[38;5;241m=\u001b[39munits, weight\u001b[38;5;241m=\u001b[39mweights\n\u001b[1;32m    489\u001b[0m         ),\n\u001b[1;32m    490\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator, n_boot\u001b[38;5;241m=\u001b[39mn_boot, seed\u001b[38;5;241m=\u001b[39mseed, errorbar\u001b[38;5;241m=\u001b[39merrorbar,\n\u001b[1;32m    491\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort, orient\u001b[38;5;241m=\u001b[39morient, err_style\u001b[38;5;241m=\u001b[39merr_style, err_kws\u001b[38;5;241m=\u001b[39merr_kws,\n\u001b[1;32m    492\u001b[0m         legend\u001b[38;5;241m=\u001b[39mlegend,\n\u001b[1;32m    493\u001b[0m     )\n\u001b[1;32m    495\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_hue(palette\u001b[38;5;241m=\u001b[39mpalette, order\u001b[38;5;241m=\u001b[39mhue_order, norm\u001b[38;5;241m=\u001b[39mhue_norm)\n\u001b[1;32m    496\u001b[0m     p\u001b[38;5;241m.\u001b[39mmap_size(sizes\u001b[38;5;241m=\u001b[39msizes, order\u001b[38;5;241m=\u001b[39msize_order, norm\u001b[38;5;241m=\u001b[39msize_norm)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/relational.py:216\u001b[0m, in \u001b[0;36m_LinePlotter.__init__\u001b[0;34m(self, data, variables, estimator, n_boot, seed, errorbar, sort, orient, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    204\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, variables\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_size_range \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    213\u001b[0m         np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m.5\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines.linewidth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    214\u001b[0m     )\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data\u001b[38;5;241m=\u001b[39mdata, variables\u001b[38;5;241m=\u001b[39mvariables)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m estimator\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrorbar \u001b[38;5;241m=\u001b[39m errorbar\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_variables(data, variables)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m PlotData(data, variables)\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_core/data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[0;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_variables(data, variables)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/seaborn/_core/data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `centralized_loss` for `y`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file in fed_avg:\n",
    "    # Read the loss file\n",
    "    df_centralized_evaluate, df_federated_evaluate = read_loss_file(file)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.lineplot(data=df_centralized_evaluate, x='round', y='centralized_loss', label='Centralized Training')\n",
    "    sns.lineplot(data=df_federated_evaluate, x='round', y='federated_evaluate_loss', label='Federated Training')\n",
    "    \n",
    "    # Set the title and labels\n",
    "    plt.title(f\"Loss vs Round (lr={df_federated_evaluate['lr'].unique()[0]})\")\n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # Show the legend\n",
    "    plt.legend()\n",
    "    # legend outside of the plot\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8a811f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>loss</th>\n",
       "      <th>centralized_accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>clipping</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1319.234096</td>\n",
       "      <td>0.267667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>354.763114</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>372.990165</td>\n",
       "      <td>0.077256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>360.498605</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>344.230190</td>\n",
       "      <td>0.069116</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>338.811768</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>325.608538</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>314.499302</td>\n",
       "      <td>0.063677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>321.373989</td>\n",
       "      <td>0.064701</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>297.027972</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>318.242571</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>286.746443</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>294.116874</td>\n",
       "      <td>0.059373</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>284.262870</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>284.933820</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>288.111328</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round         loss  centralized_accuracy    lr  batch_size  clipping  \\\n",
       "0       0  1319.234096              0.267667  0.01          32      True   \n",
       "1       1   354.763114              0.071396  0.01          32      True   \n",
       "2       2   372.990165              0.077256  0.01          32      True   \n",
       "3       3   360.498605              0.072760  0.01          32      True   \n",
       "4       4   344.230190              0.069116  0.01          32      True   \n",
       "5       5   338.811768              0.069285  0.01          32      True   \n",
       "6       6   325.608538              0.065431  0.01          32      True   \n",
       "7       7   314.499302              0.063677  0.01          32      True   \n",
       "8       8   321.373989              0.064701  0.01          32      True   \n",
       "9       9   297.027972              0.060099  0.01          32      True   \n",
       "10     10   318.242571              0.063895  0.01          32      True   \n",
       "11     11   286.746443              0.057884  0.01          32      True   \n",
       "12     12   294.116874              0.059373  0.01          32      True   \n",
       "13     13   284.262870              0.057752  0.01          32      True   \n",
       "14     14   284.933820              0.057269  0.01          32      True   \n",
       "15     15   288.111328              0.057988  0.01          32      True   \n",
       "\n",
       "                             hyperparameters         type  \n",
       "0   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "1   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "2   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "3   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "4   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "5   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "6   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "7   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "8   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "9   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "10  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "11  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "12  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "13  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "14  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "15  lr: 0.01, batch_size: 32, clipping: True  centralized  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_centralized_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4aa975cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now load the federated learning loss\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fed_avg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot centralized evaluate\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:317\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(io_open)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_modified_open\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         )\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Now load the federated learning loss\n",
    "with open(fed_avg, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Plot centralized evaluate\n",
    "df_centralized_evaluate = pd.DataFrame(data['centralized_evaluate'])\n",
    "df_federated_evaluate = pd.DataFrame(data['federated_evaluate'])\n",
    "\n",
    "# Join the two dataframes on the round\n",
    "df_centralized_evaluate['round'] = df_centralized_evaluate['round'].astype(int)\n",
    "df_federated_evaluate['round'] = df_federated_evaluate['round'].astype(int)\n",
    "\n",
    "# join the two dataframes on the round\n",
    "df = pd.merge(df_centralized_evaluate, df_federated_evaluate, on='round')\n",
    "# now plot the data\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "plt.plot(df['round'], df['centralized_loss'], label='Centralized Test Loss', color='blue')\n",
    "plt.plot(df['round'], df['federated_evaluate_loss'], label='Federated Test Loss', color='orange')\n",
    "# log scale\n",
    "\n",
    "# add legend on the outside\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.ylim(bottom=0)\n",
    "# x axis is discrete\n",
    "plt.xticks(df['round'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feaabd8",
   "metadata": {},
   "source": [
    "# Zoom in into the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_client_loss(file):\n",
    "\n",
    "    # Load JSON file\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    # Extract loss values, rounds, and epochs\n",
    "    loss_values = []\n",
    "    rounds = []\n",
    "    epochs = []\n",
    "\n",
    "    epoch_count = 0  # To keep track of epochs\n",
    "\n",
    "    for entry in data[\"client_train\"]:\n",
    "        round_number = entry[\"round\"]\n",
    "        for loss in entry[\"loss\"]:\n",
    "            rounds.append(round_number)\n",
    "            loss_values.append(loss)\n",
    "            epochs.append(epoch_count)\n",
    "            epoch_count += 1\n",
    "\n",
    "    # make it smaller \n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    # Plot loss values sequentially across rounds and epochs\n",
    "    plt.plot(epochs, loss_values, marker='o', label=\"Loss across epochs\")\n",
    "\n",
    "\n",
    "    # Add vertical lines for each round number\n",
    "    for round_number in set(rounds):\n",
    "        round_epochs = [i for i, r in enumerate(rounds) if r == round_number]\n",
    "        if round_epochs:\n",
    "            # Place a vertical line at the first epoch of each round\n",
    "            # if it is not the first round\n",
    "            if round_number != 0:\n",
    "                plt.axvline(x=round_epochs[0], color='grey', linestyle='--', label=f\"Round {round_number}\")\n",
    "\n",
    "    # Customize x-axis ticks to represent rounds\n",
    "    xticks = [i for i, round_number in enumerate(rounds) if i == 0 or rounds[i] != rounds[i-1]]\n",
    "    plt.xticks(xticks, [rounds[i] for i in xticks])\n",
    "    # log scale y \n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Local Loss (log scale)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71fc7c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../results/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32/federated_outputs/results_0.json',\n",
       "  '../results/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32/federated_outputs/results_1.json']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f.replace(\"results.json\", \"\") for f in fed_avg]\n",
    "files = [f + \"results_*.json\" for f in files]\n",
    "files = [glob.glob(f, recursive=True) for f in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9062c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
