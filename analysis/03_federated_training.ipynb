{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a77b00",
   "metadata": {},
   "source": [
    "# Federated learning monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fc68c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "# set cwd\n",
    "os.chdir(\"/Users/luisa/Desktop/nygc/cluster/projects/fl4tsf/analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "419ed36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results_luisa/periodic/federated_training/FedODE/50_rounds/rep_1-alpha_0.5-lr_0.05-batchsize_32_clipping_False/federated_outputs/results.json',\n",
       " '../results_luisa/periodic/federated_training/FedAvg/50_rounds/rep_1-alpha_0.5-lr_0.05-batchsize_32_clipping_False/federated_outputs/results.json']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_avg = glob.glob(f\"../results_luisa/**/federated_training/**/50_rounds/**/results.json\", recursive=True)\n",
    "fed_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d56d4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_loss_file(file):\n",
    "    # Read the meta.csv file\n",
    "    meta_file = file.replace(\"results.json\", \"meta.csv\")\n",
    "    meta_data = pd.read_csv(meta_file)\n",
    "    lr = meta_data['lr'].item()\n",
    "    batch_size = meta_data['batch_size'].item()\n",
    "    clipping = meta_data['gradientclipping'].item()\n",
    "    \n",
    "    # Read the results.json file\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Plot centralized evaluate\n",
    "    df_centralized_evaluate = pd.DataFrame(data['centralized_evaluate'])\n",
    "    df_federated_evaluate = pd.DataFrame(data['federated_evaluate'])\n",
    "    # Add the learning rate to the DataFrame\n",
    "    df_federated_evaluate['lr'] = lr\n",
    "    df_centralized_evaluate['lr'] = lr\n",
    "    # Add the batch size to the DataFrame\n",
    "    df_federated_evaluate['batch_size'] = batch_size\n",
    "    df_centralized_evaluate['batch_size'] = batch_size\n",
    "    # Add the clipping to the DataFrame\n",
    "    df_federated_evaluate['clipping'] = clipping\n",
    "    df_centralized_evaluate['clipping'] = clipping\n",
    "\n",
    "    # Aggregation column \n",
    "    # Check if file contins \"FedAvg\" in the path name\n",
    "    if \"FedAvg\" in file:\n",
    "        # if the path name contains \"FedAvg\" then add aggregation column \"FedAvg\"\n",
    "        df_federated_evaluate['aggregation'] = \"FedAvg\"\n",
    "        df_centralized_evaluate['aggregation'] = \"FedAvg\"\n",
    "    else:\n",
    "        # if the path name does not contain \"FedAvg\" then add aggregation column \"FedProx\"\n",
    "        df_federated_evaluate['aggregation'] = \"FedODE\"\n",
    "        df_centralized_evaluate['aggregation'] = \"FedODE\"\n",
    "\n",
    "\n",
    "    # if the path name contains \"FedAvg\" then add aggregation column \"FedAvg\"\n",
    "\n",
    "    # combine lr, batch size and clipping into one column\n",
    "    df_federated_evaluate['hyperparameters'] = df_federated_evaluate.apply(lambda x: f\"lr: {x['lr']}, batch_size: {x['batch_size']}, clipping: {x['clipping']}\", axis=1)\n",
    "    df_centralized_evaluate['hyperparameters'] = df_centralized_evaluate.apply(lambda x: f\"lr: {x['lr']}, batch_size: {x['batch_size']}, clipping: {x['clipping']}\", axis=1)\n",
    "    \n",
    "    df_federated_evaluate['type'] = \"federated\"\n",
    "    df_centralized_evaluate['type'] = \"centralized\"\n",
    "\n",
    "    # modify centralized_loss into loss\n",
    "    df_centralized_evaluate.rename(columns={'centralized_loss': 'loss'}, inplace=True)\n",
    "    # modify federated_loss into loss\n",
    "    df_federated_evaluate.rename(columns={'federated_evaluate_loss': 'loss'}, inplace=True)\n",
    "\n",
    "    return df_centralized_evaluate, df_federated_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34353c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4b168722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>loss</th>\n",
       "      <th>centralized_accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>clipping</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>type</th>\n",
       "      <th>federated_evaluate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1179.546735</td>\n",
       "      <td>0.236395</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439.925084</td>\n",
       "      <td>0.090120</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>418.019392</td>\n",
       "      <td>0.086213</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>621.714007</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>345.576939</td>\n",
       "      <td>0.070882</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedODE</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>centralized</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>657.443583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.139232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>673.477051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.135910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>714.911906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.144730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>690.752157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.139070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>691.760457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>lr: 0.05, batch_size: 32, clipping: False</td>\n",
       "      <td>federated</td>\n",
       "      <td>0.139348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    round         loss  centralized_accuracy    lr  batch_size  clipping  \\\n",
       "0       0  1179.546735              0.236395  0.05          32     False   \n",
       "1       1   439.925084              0.090120  0.05          32     False   \n",
       "2       2   418.019392              0.086213  0.05          32     False   \n",
       "3       3   621.714007              0.133085  0.05          32     False   \n",
       "4       4   345.576939              0.070882  0.05          32     False   \n",
       "..    ...          ...                   ...   ...         ...       ...   \n",
       "45     46   657.443583                   NaN  0.05          32     False   \n",
       "46     47   673.477051                   NaN  0.05          32     False   \n",
       "47     48   714.911906                   NaN  0.05          32     False   \n",
       "48     49   690.752157                   NaN  0.05          32     False   \n",
       "49     50   691.760457                   NaN  0.05          32     False   \n",
       "\n",
       "   aggregation                            hyperparameters         type  \\\n",
       "0       FedODE  lr: 0.05, batch_size: 32, clipping: False  centralized   \n",
       "1       FedODE  lr: 0.05, batch_size: 32, clipping: False  centralized   \n",
       "2       FedODE  lr: 0.05, batch_size: 32, clipping: False  centralized   \n",
       "3       FedODE  lr: 0.05, batch_size: 32, clipping: False  centralized   \n",
       "4       FedODE  lr: 0.05, batch_size: 32, clipping: False  centralized   \n",
       "..         ...                                        ...          ...   \n",
       "45      FedAvg  lr: 0.05, batch_size: 32, clipping: False    federated   \n",
       "46      FedAvg  lr: 0.05, batch_size: 32, clipping: False    federated   \n",
       "47      FedAvg  lr: 0.05, batch_size: 32, clipping: False    federated   \n",
       "48      FedAvg  lr: 0.05, batch_size: 32, clipping: False    federated   \n",
       "49      FedAvg  lr: 0.05, batch_size: 32, clipping: False    federated   \n",
       "\n",
       "    federated_evaluate_accuracy  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  \n",
       "..                          ...  \n",
       "45                     0.139232  \n",
       "46                     0.135910  \n",
       "47                     0.144730  \n",
       "48                     0.139070  \n",
       "49                     0.139348  \n",
       "\n",
       "[202 rows x 10 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_centralized_evaluate = pd.DataFrame()\n",
    "df_federated_evaluate = pd.DataFrame()\n",
    "for file in fed_avg:\n",
    "    df_centralized_evaluate_temp, df_federated_evaluate_temp = read_loss_file(file)\n",
    "    df_centralized_evaluate = pd.concat([df_centralized_evaluate, df_centralized_evaluate_temp])\n",
    "    df_federated_evaluate = pd.concat([df_federated_evaluate, df_federated_evaluate_temp])\n",
    "# plot the loss\n",
    "# plot the loss by hyperparameters\n",
    "# merge the two dataframes\n",
    "# append dataframes\n",
    "df = pd.concat([df_centralized_evaluate, df_federated_evaluate])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fb16d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lr 0.01 batch size 32 clipping True \n",
    "df_test = df[df['hyperparameters'] == \"lr: 0.01, batch_size: 32, clipping: False\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7fb746f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_40663/1951150924.py:2: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_40663/1951150924.py:10: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(\n",
      "/var/folders/yx/rfhrpk093hz1gfwtn7qxt_180000gq/T/ipykernel_40663/1951150924.py:26: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(title = \"lr, clipping, batch size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.lineplot(\n",
    "    data=df_test[df_test['type'] == \"federated\"],\n",
    "    x='round',\n",
    "    y='loss',\n",
    "    hue='aggregation',  # Automatically creates different colors\n",
    "    palette='tab10'  # Optional: choose color palette\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_test[df_test['type'] == \"centralized\"],\n",
    "    x='round',\n",
    "    y='loss',\n",
    "    hue='aggregation',  # Automatically creates different colors\n",
    "    palette='tab10'  # Optional: choose color palette\n",
    ")\n",
    "\n",
    "plt.ylim(bottom=0)\n",
    "plt.xticks(ticks=range(0, df_federated_evaluate['round'].max() + 1, 25))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Centralized Training Loss')\n",
    "plt.tight_layout()\n",
    "# log y\n",
    "# legend outside\n",
    "plt.legend(title = \"lr, clipping, batch size\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# x log\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8a811f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>loss</th>\n",
       "      <th>centralized_accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>clipping</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1319.234096</td>\n",
       "      <td>0.267667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>354.763114</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>372.990165</td>\n",
       "      <td>0.077256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>360.498605</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>344.230190</td>\n",
       "      <td>0.069116</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>338.811768</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>325.608538</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>314.499302</td>\n",
       "      <td>0.063677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>321.373989</td>\n",
       "      <td>0.064701</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>297.027972</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>318.242571</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>286.746443</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>294.116874</td>\n",
       "      <td>0.059373</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>284.262870</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>284.933820</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>288.111328</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>lr: 0.01, batch_size: 32, clipping: True</td>\n",
       "      <td>centralized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round         loss  centralized_accuracy    lr  batch_size  clipping  \\\n",
       "0       0  1319.234096              0.267667  0.01          32      True   \n",
       "1       1   354.763114              0.071396  0.01          32      True   \n",
       "2       2   372.990165              0.077256  0.01          32      True   \n",
       "3       3   360.498605              0.072760  0.01          32      True   \n",
       "4       4   344.230190              0.069116  0.01          32      True   \n",
       "5       5   338.811768              0.069285  0.01          32      True   \n",
       "6       6   325.608538              0.065431  0.01          32      True   \n",
       "7       7   314.499302              0.063677  0.01          32      True   \n",
       "8       8   321.373989              0.064701  0.01          32      True   \n",
       "9       9   297.027972              0.060099  0.01          32      True   \n",
       "10     10   318.242571              0.063895  0.01          32      True   \n",
       "11     11   286.746443              0.057884  0.01          32      True   \n",
       "12     12   294.116874              0.059373  0.01          32      True   \n",
       "13     13   284.262870              0.057752  0.01          32      True   \n",
       "14     14   284.933820              0.057269  0.01          32      True   \n",
       "15     15   288.111328              0.057988  0.01          32      True   \n",
       "\n",
       "                             hyperparameters         type  \n",
       "0   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "1   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "2   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "3   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "4   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "5   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "6   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "7   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "8   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "9   lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "10  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "11  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "12  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "13  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "14  lr: 0.01, batch_size: 32, clipping: True  centralized  \n",
       "15  lr: 0.01, batch_size: 32, clipping: True  centralized  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_centralized_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4aa975cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now load the federated learning loss\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fed_avg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot centralized evaluate\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:317\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(io_open)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_modified_open\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         )\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Now load the federated learning loss\n",
    "with open(fed_avg, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Plot centralized evaluate\n",
    "df_centralized_evaluate = pd.DataFrame(data['centralized_evaluate'])\n",
    "df_federated_evaluate = pd.DataFrame(data['federated_evaluate'])\n",
    "\n",
    "# Join the two dataframes on the round\n",
    "df_centralized_evaluate['round'] = df_centralized_evaluate['round'].astype(int)\n",
    "df_federated_evaluate['round'] = df_federated_evaluate['round'].astype(int)\n",
    "\n",
    "# join the two dataframes on the round\n",
    "df = pd.merge(df_centralized_evaluate, df_federated_evaluate, on='round')\n",
    "# now plot the data\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "plt.plot(df['round'], df['centralized_loss'], label='Centralized Test Loss', color='blue')\n",
    "plt.plot(df['round'], df['federated_evaluate_loss'], label='Federated Test Loss', color='orange')\n",
    "# log scale\n",
    "\n",
    "# add legend on the outside\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.ylim(bottom=0)\n",
    "# x axis is discrete\n",
    "plt.xticks(df['round'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feaabd8",
   "metadata": {},
   "source": [
    "# Zoom in into the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_client_loss(file):\n",
    "\n",
    "    # Load JSON file\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "    # Extract loss values, rounds, and epochs\n",
    "    loss_values = []\n",
    "    rounds = []\n",
    "    epochs = []\n",
    "\n",
    "    epoch_count = 0  # To keep track of epochs\n",
    "\n",
    "    for entry in data[\"client_train\"]:\n",
    "        round_number = entry[\"round\"]\n",
    "        for loss in entry[\"loss\"]:\n",
    "            rounds.append(round_number)\n",
    "            loss_values.append(loss)\n",
    "            epochs.append(epoch_count)\n",
    "            epoch_count += 1\n",
    "\n",
    "    # make it smaller \n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    # Plot loss values sequentially across rounds and epochs\n",
    "    plt.plot(epochs, loss_values, marker='o', label=\"Loss across epochs\")\n",
    "\n",
    "\n",
    "    # Add vertical lines for each round number\n",
    "    for round_number in set(rounds):\n",
    "        round_epochs = [i for i, r in enumerate(rounds) if r == round_number]\n",
    "        if round_epochs:\n",
    "            # Place a vertical line at the first epoch of each round\n",
    "            # if it is not the first round\n",
    "            if round_number != 0:\n",
    "                plt.axvline(x=round_epochs[0], color='grey', linestyle='--', label=f\"Round {round_number}\")\n",
    "\n",
    "    # Customize x-axis ticks to represent rounds\n",
    "    xticks = [i for i, round_number in enumerate(rounds) if i == 0 or rounds[i] != rounds[i-1]]\n",
    "    plt.xticks(xticks, [rounds[i] for i in xticks])\n",
    "    # log scale y \n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(\"Local Loss (log scale)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71fc7c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../results/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32/federated_outputs/results_0.json',\n",
       "  '../results/periodic/federated_training/FedAvg/15_rounds/rep_1-alpha_0.5-lr_0.01-batchsize_32/federated_outputs/results_1.json']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f.replace(\"results.json\", \"\") for f in fed_avg]\n",
    "files = [f + \"results_*.json\" for f in files]\n",
    "files = [glob.glob(f, recursive=True) for f in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9062c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
