params {
    epochs = "300"
    lr = "0.01,0.001" // 0.1,0.01,0.001
    lrdecay = "1.0" // 1.0,0.99,0.5,0.01
    batch_size = "32" //16,32,50,64,100

    use_gpu = true

    serverrounds = "100"
    localepochs = "3,10,20"

    aggregation = "FedAvg"
    clients = "2"
    alpha = 0.5
    replicate = 1
    skip_centralized = true
    skip_federated = false
    gradient_clipping = "False"
    outdir = "./results_federated_learningtest"
}