params {

    skip_centralized = true
    use_gpu = true

    skip_federated = false

    lrdecay = "1.0" // 1.0,0.99,0.5,0.01

    lr = "0.01,0.001,0.0001" // 0.1,0.01,0.001
    batch_size = "16,32,64" //16,32,50,64,100

    serverrounds = "150"
    localepochs = "3,5,10,20"
    decay_onset = "10,15,30"

    aggregation = "FedAvg"
    clients = "2"
    alpha = 0.5
    replicate = 1
    
    
    gradient_clipping = "False"
    outdir = "./results_federated_learningtest_hyperparam"
}