params {

    skip_centralized = true
    use_gpu = true

    lr = "0.01,0.001,0.0001" // 0.1,0.01,0.001
    lrdecay = "1.0" // 1.0,0.99,0.5,0.01
    batch_size = "16,32,64" //16,32,50,64,100

    serverrounds = "100"
    localepochs = "3,5,10,20"

    aggregation = "FedAvg"
    clients = "2"
    alpha = 0.5
    replicate = 1
    
    skip_federated = false
    gradient_clipping = "False"
    outdir = "./results_federated_learningtest_new"
}